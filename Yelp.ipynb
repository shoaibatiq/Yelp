{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import xlrd\n",
    "import lxml\n",
    "from time import sleep\n",
    "from xlsxwriter import Workbook\n",
    "import requests\n",
    "\n",
    "\n",
    "#--------------------------Search-------------------------\n",
    "def search(keyword='Resturants',where='Chicago'):\n",
    "    driver=webdriver.Chrome('chromedriver')\n",
    "    url='https://www.yelp.com'\n",
    "    driver.get(url)\n",
    "    sleep(1)\n",
    "    driver.find_element_by_id('find_desc').send_keys(keyword)\n",
    "    btn=driver.find_element_by_id('dropperText_Mast')\n",
    "    btn.clear()\n",
    "    btn.send_keys(where)\n",
    "    btn.submit()\n",
    "    url=driver.current_url\n",
    "    driver.close()\n",
    "    return url\n",
    "\n",
    "#------------------------------filtered links--------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def get_filtered(url):\n",
    "    driver=webdriver.Chrome('chromedriver')\n",
    "    c=0\n",
    "    flag=True\n",
    "    filterd=[]\n",
    "    count=0\n",
    "    end=5\n",
    "    condition=True\n",
    "    while flag:\n",
    "        driver.get(url)\n",
    "        btn=driver.find_element_by_xpath('//span[@class=\"lemon--span__373c0__3997G filter__373c0__wBU2H\"]')\n",
    "        btn.click()\n",
    "        sleep(2)\n",
    "        btn=driver.find_element_by_xpath('//button[@class=\"link__373c0__29O4k\"]//p[@class=\"lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--inherit__373c0__w_15m text-align--left__373c0__2pnx_ text-size--small__373c0__3SGMi\"]')\n",
    "        btn.click()\n",
    "        sleep(1)\n",
    "        div=driver.find_element_by_xpath('//div[@class=\"lemon--div__373c0__1mboc u-padding-t4 u-padding-r6 u-padding-b6 u-padding-l6 border-color--default__373c0__2oFDT\"]')\n",
    "        inputslis=div.find_elements_by_tag_name('input')\n",
    "        search=driver.find_element_by_xpath('//button[@class=\"button__373c0__3yl_n small__373c0__1sSnK primary__373c0__oJujF\"]')\n",
    "        length=len(inputslis)\n",
    "        if condition:\n",
    "            print('length',length)\n",
    "            condition=False\n",
    "\n",
    "                        #x  x+5\n",
    "        for i in range(count,end):\n",
    "\n",
    "            try:\n",
    "                if count==length:\n",
    "                    break\n",
    "                inputslis[count].click()\n",
    "                print('count=',count)\n",
    "                count+=1\n",
    "                c+=1\n",
    "\n",
    "            except:\n",
    "                print(\" Error\")\n",
    "                flag=False\n",
    "                print('c=',c)\n",
    "\n",
    "        end+=5\n",
    "\n",
    "        search.click()\n",
    "        sleep(5)\n",
    "        filterd.append(driver.current_url)\n",
    "        if count==length:\n",
    "            break\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "\n",
    "    return list(set(filterd))\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------get listing links----------------------\n",
    "\n",
    "class Source:\n",
    "    def __init__(self,source):\n",
    "        self.source=source\n",
    "        self.final=[]\n",
    "        self.get_links()\n",
    "    def no_of_results(self,link):\n",
    "        res0=requests.get(link)\n",
    "        soup0=BeautifulSoup(res0.content,'lxml')\n",
    "        soup0.find\n",
    "        result0=soup0.find('h1',class_=\"lemon--h1__373c0__2ZHSL heading--h2__373c0__1TQtb alternate__373c0__1uacp\")\n",
    "        result0=result0.next_sibling.text\n",
    "        string=result0\n",
    "        f_start=string.find('f')\n",
    "        nor=int(string[f_start+2:])\n",
    "        _=string.find('-')\n",
    "        per_p=int(string[_+1:f_start-1])\n",
    "        return [nor,per_p]\n",
    "    def get_links(self):\n",
    "        for inde,link in enumerate(self.source):\n",
    "            print(('Source\\t'+str(inde)).center(100,'-'))\n",
    "            datip=self.no_of_results(link)\n",
    "            nor=datip[0]\n",
    "            per_p=datip[1]\n",
    "            print('No. of results:',nor)\n",
    "            print('Required Itterations:',int(nor/per_p))\n",
    "            c=0\n",
    "            countt=0\n",
    "            while c<=nor:\n",
    "                link=self.source[inde]\n",
    "                print('----------------------------itteration:',int(c/per_p))\n",
    "                print('c  =',c)\n",
    "                if c==0:\n",
    "                    link=link\n",
    "                else:\n",
    "                    link=link+\"&start=\"+str(c)\n",
    "\n",
    "                response=requests.get(link)\n",
    "                soup=BeautifulSoup(response.content,'lxml')\n",
    "                try:\n",
    "                    resturants=soup.find_all('div',class_=\"lemon--div__373c0__1mboc u-padding-t3 u-padding-b3 border--top__373c0__19Owr border-color--default__373c0__2oFDT\")\n",
    "                    print('B_res:',len(resturants))\n",
    "                except:\n",
    "                    print('Failed to find resturants')\n",
    "                    resturants=[]\n",
    "                try:\n",
    "                    first=list(soup.find_all('div',class_=\"lemon--div__373c0__1mboc u-padding-t3 u-padding-b3 border-color--default__373c0__2oFDT\")[-1])\n",
    "                except:\n",
    "                    print('Failed to find first')\n",
    "                    first=[]\n",
    "                resturants=first+resturants\n",
    "                countt+=len(resturants)\n",
    "                print('Got:',len(resturants))\n",
    "                print('Total:',countt)\n",
    "                gog=['https://www.yelp.com'+div.find('a')['href'] for div in resturants]\n",
    "                self.final+=gog\n",
    "                c+=per_p\n",
    "#------------------------------------------------------------------------------------------------\n",
    "what=input(\"Enter search keywords:\")\n",
    "where=input('Enter Location:')\n",
    "url=search(what,where)\n",
    "source=get_filtered(url)\n",
    "get=Source(source)\n",
    "k=get.final\n",
    "uniq=set(k)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "workbookin=Workbook('stored_data1.xlsx')\n",
    "worksheetin=workbookin.add_worksheet()\n",
    "\n",
    "rowno=0\n",
    "links=list(uniq)\n",
    "driver=webdriver.Chrome('chromedriver')\n",
    "for index,link in enumerate(links):\n",
    "    print('processing link:',index+1)\n",
    "    driver.get(link)\n",
    "    sleep(2)\n",
    "    try:\n",
    "        btn=driver.find_element_by_partial_link_text('More Attributes')\n",
    "        btn.click()\n",
    "    except:\n",
    "        print('No \"More Attributes\" Button found')\n",
    "        pass\n",
    "    soup=BeautifulSoup(driver.page_source,'lxml')\n",
    "    try:\n",
    "        print('getting name')\n",
    "        name=soup.find('h1').text\n",
    "    except:\n",
    "        print('name not found')\n",
    "        name=None\n",
    "    try:\n",
    "        print('getting category')\n",
    "        maybe=soup.find('span',class_=\"lemon--span__373c0__3997G display--inline__373c0__1DbOG u-space-r1 border-color--default__373c0__2oFDT\").text\n",
    "        if maybe.find('$') != -1:\n",
    "            span=soup.find('span',class_=\"lemon--span__373c0__3997G display--inline__373c0__1DbOG u-space-r1 border-color--default__373c0__2oFDT\").next_sibling\n",
    "            span=span.find_all('span')\n",
    "            category=''.join([span[i].text for i in range(len(span))])\n",
    "        else:\n",
    "            category=maybe\n",
    "    except:\n",
    "        print('category not found')\n",
    "        category=None\n",
    "    try:\n",
    "        print('getting adress')\n",
    "        spans=soup.find('address',class_=\"lemon--address__373c0__2sPac\").find_all('span')\n",
    "        adress=''\n",
    "        for span in spans:\n",
    "            adress+=span.text\n",
    "    except:\n",
    "        print('adress not found')\n",
    "        adress=None\n",
    "    try:\n",
    "        print('getting telephone number')\n",
    "        span=soup.find_all('p',class_=\"lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--normal__373c0__K_MKN text-align--left__373c0__2pnx_\")\n",
    "        tel=span[-2].text\n",
    "        tele=(tel.replace('(','').replace(')',''))\n",
    "        int(tele.replace(' ','').replace('-',''))\n",
    "    \n",
    "    except:\n",
    "        print('telephone number not found')\n",
    "        tel=None\n",
    "\n",
    "    try:\n",
    "        print('getting attributes')\n",
    "        attribute=[]\n",
    "        for i in range(len(section)):\n",
    "            try:\n",
    "                attribute.append(section[i].find('div',class_=\"lemon--div__373c0__1mboc u-space-b2 arrange__373c0__UHqhV vertical-align-middle__373c0__2TQsQ border-color--default__373c0__2oFDT\").next_sibling.find('div',class_=\"lemon--div__373c0__1mboc border-color--default__373c0__2oFDT\").find('div',class_=\"lemon--div__373c0__1mboc u-space-b3 border-color--default__373c0__2oFDT\").find('div',class_=\"lemon--div__373c0__1mboc arrange__373c0__UHqhV gutter-12__373c0__3kguh layout-wrap__373c0__34d4b layout-2-units__373c0__3CiAk border-color--default__373c0__2oFDT\"))\n",
    "            except:\n",
    "                pass\n",
    "        attribute=attribute[0]\n",
    "        attribute=attribute.find_all('div',class_=\"lemon--div__373c0__1mboc arrange-unit__373c0__1piwO border-color--default__373c0__2oFDT\")\n",
    "        attributes=[attribute[i].div for i in range(len(attribute)) if attribute[i].div is not None ]\n",
    "        attr_dict=[]\n",
    "        for i in range(len(attributes)):\n",
    "            div=attributes[i].div.next_sibling\n",
    "            attr_dict.append({div.span.text:div.span.next_sibling.text[1:]})\n",
    "        \n",
    "    except:\n",
    "        print('attributes not found')\n",
    "        attr_dict=None\n",
    "    try:\n",
    "        print('getting timings')\n",
    "        section=soup.find_all('section',class_=\"lemon--section__373c0__fNwDM u-space-t4 u-padding-t4 border--top__373c0__19Owr border-color--default__373c0__2oFDT\")\n",
    "        for i in section:\n",
    "            try:\n",
    "                sect=i.div.next_sibling.div.next_sibling.find('div',class_=\"lemon--div__373c0__1mboc border-color--default__373c0__2oFDT\").find('div',class_=\"lemon--div__373c0__1mboc border-color--default__373c0__2oFDT\")\n",
    "            except:\n",
    "                pass\n",
    "        tr=sect.table.tbody.find_all('tr')\n",
    "        time_dict=[]\n",
    "        for i in range(len(tr)):\n",
    "            time_dict.append({tr[i].th.p.text:tr[i].td.ul.li.p.text})\n",
    "        try:\n",
    "            if list(attr_dict[0].keys())[0]=='Health Score':\n",
    "                score=list(attr_dict[0].values())[0]\n",
    "                attr_dict.pop(0)\n",
    "            else:\n",
    "                score=None\n",
    "\n",
    "        except:\n",
    "            score=None\n",
    "\n",
    "    except:\n",
    "        print('timings not found')\n",
    "        time_dict=None\n",
    "    try:\n",
    "        print('getting claimed?')\n",
    "        claimed=soup.find('h1').next_sibling.span.text\n",
    "    except:\n",
    "        print('claimed? not found')\n",
    "        claimed=None\n",
    "    try:\n",
    "        print('getting reviews')\n",
    "        reviews=soup.find('h1').parent.next_sibling.div.next_sibling.p.text\n",
    "    except:\n",
    "        print('reviews not found')\n",
    "        reviews= None\n",
    "    try:\n",
    "        print('getting website address')\n",
    "        span=soup.find_all('p',class_=\"lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--normal__373c0__K_MKN text-align--left__373c0__2pnx_\")\n",
    "        a=span[-2].parent.parent.parent.previous_sibling.div.div.next_sibling.a.text\n",
    "        site='https://www.'+a\n",
    "    except:\n",
    "        print('website address not found')\n",
    "        site=None\n",
    "    try:\n",
    "        print('getting ratings')\n",
    "        rating=soup.find('h1').parent.next_sibling.div.span.div['aria-label']\n",
    "        end=rating.find('r')+1\n",
    "        rating=rating[:end]\n",
    "    except:\n",
    "        print('ratings not found')\n",
    "        rating=None\n",
    "    for coulmn,item in enumerate([name,category,adress,tel,score,str(attr_dict),str(time_dict),rating,claimed,reviews,site,link]):\n",
    "        worksheetin.write(rowno,coulmn,item)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    rowno+=1 \n",
    "    #sleep(8)\n",
    "    \n",
    "print('closing.....')\n",
    "driver.close()\n",
    "workbookin.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
